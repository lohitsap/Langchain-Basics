
# first code in stroutput parser series
# we will use dynamic prompt template to generate a report on a topic

'''
Structure :

give Prompt 1 : Detailed report on a topic

give Prompt 2 : Extract response and take Summary of the report generated by LLM

'''

from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
load_dotenv()
from langchain_core.prompts import PromptTemplate


model = ChatOpenAI(model="gpt-4o-2024-08-06")


# give Prompt 1 : Detailed report on a topic
template1 = PromptTemplate(
    template="Generate a detailed report on the topic: {topic}",
    input_variables=["topic"]
)

# give Prompt 2 : Extract response and take Summary of the report generated by LLM
template2 = PromptTemplate(
    template="Write a 5 line summary on the following text. /n {text}",
    input_variables=["text"]
)

# first send template1 in the prompt

prompt1 = template1.invoke({"topic": "black holes"})
# send this to model now
result = model.invoke(prompt1)

# make prompt 2
prompt2 = template2.invoke({"text": result.content})
# send this 2nd prompt to the model

result1 = model.invoke(prompt2)

# finally print the result
print(result1.content) 

'''
You can check in the output, you got the 5 line summary of the report generated by LLM.

Now, we will re-write this code with help of StrOutputParser.
For this, you can refer stroutputparser1.py code file.
'''